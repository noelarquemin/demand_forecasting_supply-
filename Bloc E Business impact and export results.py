# -*- coding: utf-8 -*-
"""Untitled65.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BgjgYUdY6fMgFrC3XxZzrkBupiGkGu38
"""

# ============================================================================
# IMPORTS (Additional for Block E)
# ============================================================================
from datetime import datetime

print("\n" + "=" * 80)
print("BLOCK E: BUSINESS IMPACT & EXPORT")
print("=" * 80)

# ============================================================================
# 1. TECHNICAL METRICS FOR ALL FORECAST MODELS (j+1)
# ============================================================================
print("\n[1] CALCULATING TECHNICAL METRICS FOR j+1 HORIZON...")

# Prepare test data for evaluation
test_eval = test_df_clean.copy()

# Define all forecast models to evaluate
forecast_models_j1 = {
    'Naïve (j-1)': 'Baseline_Naive',
    'Naïve Season (j-7)': 'Baseline_Naive_Season',
    'Moving Avg (7d)': 'Baseline_MA7',
    'Dataset Forecast': 'Baseline_Dataset',
    'XGBoost ML': 'Pred_XGB_j1'
}

# Calculate technical metrics for all models
technical_metrics_j1_list = []

for model_name, forecast_col in forecast_models_j1.items():
    if forecast_col not in test_eval.columns:
        print(f"  Warning: {forecast_col} not found, skipping {model_name}")
        continue

    y_true = test_eval['Units_Sold_j1']
    y_pred = test_eval[forecast_col]

    metrics = calculate_metrics(y_true, y_pred, model_name)

    if metrics:
        metrics['SMAPE'] = calculate_smape(y_true.values, y_pred.values)
        technical_metrics_j1_list.append(metrics)

technical_metrics_j1_df = pd.DataFrame(technical_metrics_j1_list)

print("\nTechnical Metrics (j+1 Horizon):")
print(technical_metrics_j1_df[['Model', 'MAE', 'RMSE', 'SMAPE', 'WAPE']].to_string(index=False))

# ============================================================================
# 2. RUN INVENTORY SIMULATIONS FOR ALL BASELINE MODELS (j+1)
# ============================================================================
print("\n" + "=" * 80)
print("[2] RUNNING INVENTORY SIMULATIONS FOR ALL MODELS (j+1)")
print("=" * 80)

# Run simulations for all baseline models
print("\n[2.1] Naïve (j-1) simulation...")

naive_sim_results = []

for sku_id in tqdm(unique_skus, desc="Naïve Sim"):
    sku_data = test_df_clean[test_df_clean['SKU_ID'] == sku_id].sort_values('Date')

    if len(sku_data) == 0:
        continue

    sku_info_row = sku_params[sku_params['SKU_ID'] == sku_id]
    if len(sku_info_row) == 0:
        continue
    sku_info_row = sku_info_row.iloc[0]

    supplier_id = sku_info_row['Supplier_ID']
    supplier_lead_dist = supplier_leadtime_dist.get(supplier_id, np.array([7]))

    sku_info = {
        'initial_inventory': sku_info_row['initial_inventory'],
        'reorder_point': sku_info_row['reorder_point'],
        'reorder_quantity': sku_info_row['reorder_quantity'],
        'avg_lead_time': sku_info_row['avg_lead_time'],
        'unit_cost': sku_info_row['unit_cost'],
        'unit_price': sku_info_row['unit_price']
    }

    demand_forecast = sku_data['Baseline_Naive'].fillna(0).values

    result = simulate_inventory(
        sku_id=sku_id,
        demand_forecast=demand_forecast,
        sku_info=sku_info,
        supplier_lead_dist=supplier_lead_dist,
        use_monte_carlo=False
    )

    result['ABC_Class'] = sku_info_row['ABC_Class']
    result['XYZ_Class'] = sku_info_row['XYZ_Class']
    naive_sim_results.append(result)

naive_sim_df = pd.DataFrame(naive_sim_results)
print(f"Completed: {len(naive_sim_df)} SKUs")

print("\n[2.2] Naïve Season (j-7) simulation...")

naive_season_sim_results = []

for sku_id in tqdm(unique_skus, desc="Naïve Season Sim"):
    sku_data = test_df_clean[test_df_clean['SKU_ID'] == sku_id].sort_values('Date')

    if len(sku_data) == 0:
        continue

    sku_info_row = sku_params[sku_params['SKU_ID'] == sku_id]
    if len(sku_info_row) == 0:
        continue
    sku_info_row = sku_info_row.iloc[0]

    supplier_id = sku_info_row['Supplier_ID']
    supplier_lead_dist = supplier_leadtime_dist.get(supplier_id, np.array([7]))

    sku_info = {
        'initial_inventory': sku_info_row['initial_inventory'],
        'reorder_point': sku_info_row['reorder_point'],
        'reorder_quantity': sku_info_row['reorder_quantity'],
        'avg_lead_time': sku_info_row['avg_lead_time'],
        'unit_cost': sku_info_row['unit_cost'],
        'unit_price': sku_info_row['unit_price']
    }

    demand_forecast = sku_data['Baseline_Naive_Season'].fillna(0).values

    result = simulate_inventory(
        sku_id=sku_id,
        demand_forecast=demand_forecast,
        sku_info=sku_info,
        supplier_lead_dist=supplier_lead_dist,
        use_monte_carlo=False
    )

    result['ABC_Class'] = sku_info_row['ABC_Class']
    result['XYZ_Class'] = sku_info_row['XYZ_Class']
    naive_season_sim_results.append(result)

naive_season_sim_df = pd.DataFrame(naive_season_sim_results)
print(f"Completed: {len(naive_season_sim_df)} SKUs")

print("\n[2.3] Moving Average simulation...")

ma_sim_results = []

for sku_id in tqdm(unique_skus, desc="MA Sim"):
    sku_data = test_df_clean[test_df_clean['SKU_ID'] == sku_id].sort_values('Date')

    if len(sku_data) == 0:
        continue

    sku_info_row = sku_params[sku_params['SKU_ID'] == sku_id]
    if len(sku_info_row) == 0:
        continue
    sku_info_row = sku_info_row.iloc[0]

    supplier_id = sku_info_row['Supplier_ID']
    supplier_lead_dist = supplier_leadtime_dist.get(supplier_id, np.array([7]))

    sku_info = {
        'initial_inventory': sku_info_row['initial_inventory'],
        'reorder_point': sku_info_row['reorder_point'],
        'reorder_quantity': sku_info_row['reorder_quantity'],
        'avg_lead_time': sku_info_row['avg_lead_time'],
        'unit_cost': sku_info_row['unit_cost'],
        'unit_price': sku_info_row['unit_price']
    }

    demand_forecast = sku_data['Baseline_MA7'].fillna(0).values

    result = simulate_inventory(
        sku_id=sku_id,
        demand_forecast=demand_forecast,
        sku_info=sku_info,
        supplier_lead_dist=supplier_lead_dist,
        use_monte_carlo=False
    )

    result['ABC_Class'] = sku_info_row['ABC_Class']
    result['XYZ_Class'] = sku_info_row['XYZ_Class']
    ma_sim_results.append(result)

ma_sim_df = pd.DataFrame(ma_sim_results)
print(f"Completed: {len(ma_sim_df)} SKUs")

print("\n[2.4] Dataset Forecast simulation...")

dataset_sim_results = []

for sku_id in tqdm(unique_skus, desc="Dataset Sim"):
    sku_data = test_df_clean[test_df_clean['SKU_ID'] == sku_id].sort_values('Date')

    if len(sku_data) == 0:
        continue

    sku_info_row = sku_params[sku_params['SKU_ID'] == sku_id]
    if len(sku_info_row) == 0:
        continue
    sku_info_row = sku_info_row.iloc[0]

    supplier_id = sku_info_row['Supplier_ID']
    supplier_lead_dist = supplier_leadtime_dist.get(supplier_id, np.array([7]))

    sku_info = {
        'initial_inventory': sku_info_row['initial_inventory'],
        'reorder_point': sku_info_row['reorder_point'],
        'reorder_quantity': sku_info_row['reorder_quantity'],
        'avg_lead_time': sku_info_row['avg_lead_time'],
        'unit_cost': sku_info_row['unit_cost'],
        'unit_price': sku_info_row['unit_price']
    }

    demand_forecast = sku_data['Baseline_Dataset'].fillna(0).values

    result = simulate_inventory(
        sku_id=sku_id,
        demand_forecast=demand_forecast,
        sku_info=sku_info,
        supplier_lead_dist=supplier_lead_dist,
        use_monte_carlo=False
    )

    result['ABC_Class'] = sku_info_row['ABC_Class']
    result['XYZ_Class'] = sku_info_row['XYZ_Class']
    dataset_sim_results.append(result)

dataset_sim_df = pd.DataFrame(dataset_sim_results)
print(f"Completed: {len(dataset_sim_df)} SKUs")

print("\nAll baseline simulations complete")

# ============================================================================
# 3. AGGREGATE BUSINESS KPIs WITH DEMAND WEIGHTING (j+1)
# ============================================================================
print("\n" + "=" * 80)
print("[3] AGGREGATING BUSINESS KPIs (j+1, DEMAND-WEIGHTED)")
print("=" * 80)

def aggregate_kpis_weighted(sim_df, model_name):
    """Aggregate KPIs with demand weighting"""
    if len(sim_df) == 0:
        return None

    total_demand_all = sim_df['total_demand'].sum()
    if total_demand_all == 0:
        return None

    sim_df = sim_df.copy()
    sim_df['weight'] = sim_df['total_demand'] / total_demand_all

    weighted_fill_rate = (sim_df['fill_rate'] * sim_df['weight']).sum()
    weighted_stockout_rate = (sim_df['stockout_rate'] * sim_df['weight']).sum()

    total_holding_cost = sim_df['holding_cost'].sum()
    total_stockout_cost = sim_df['stockout_cost'].sum()
    total_cost = sim_df['total_cost'].sum()

    return {
        'Model': model_name,
        'Fill_Rate_%': weighted_fill_rate,
        'Stockout_Rate_%': weighted_stockout_rate,
        'Holding_Cost_€': total_holding_cost,
        'Stockout_Cost_€': total_stockout_cost,
        'Total_Cost_€': total_cost
    }

business_kpis_j1_list = []

business_kpis_j1_list.append(aggregate_kpis_weighted(naive_sim_df, 'Naïve (j-1)'))
business_kpis_j1_list.append(aggregate_kpis_weighted(naive_season_sim_df, 'Naïve Season (j-7)'))
business_kpis_j1_list.append(aggregate_kpis_weighted(ma_sim_df, 'Moving Avg (7d)'))
business_kpis_j1_list.append(aggregate_kpis_weighted(dataset_sim_df, 'Dataset Forecast'))
business_kpis_j1_list.append(aggregate_kpis_weighted(xgb_sim_df, 'XGBoost ML'))

business_kpis_j1_list = [x for x in business_kpis_j1_list if x is not None]
business_kpis_j1_df = pd.DataFrame(business_kpis_j1_list)

print("\nBusiness KPIs (j+1, Demand-Weighted):")
print(business_kpis_j1_df.to_string(index=False))

# ============================================================================
# 4. CREATE COMPARISON TABLE (j+1)
# ============================================================================
print("\n[4] CREATING COMPARISON TABLE (j+1)...")

comparison_j1_table = technical_metrics_j1_df.merge(
    business_kpis_j1_df,
    on='Model',
    how='outer'
)

comparison_j1_columns = [
    'Model', 'RMSE', 'SMAPE', 'Fill_Rate_%', 'Stockout_Rate_%',
    'Holding_Cost_€', 'Stockout_Cost_€', 'Total_Cost_€', 'WAPE'
]

comparison_j1_table = comparison_j1_table[comparison_j1_columns]

print("\nComparison Table (j+1):")
print(comparison_j1_table.to_string(index=False))

# ============================================================================
# 5. MEASURE IMPROVEMENTS FROM ML MODEL (j+1)
# ============================================================================
print("\n[5] MEASURING ML IMPROVEMENTS (j+1)...")

ml_j1_results = comparison_j1_table[comparison_j1_table['Model'].str.contains('XGBoost|ML')]
if len(ml_j1_results) > 0:
    ml_j1_results = ml_j1_results.iloc[0]

    baseline_j1_results = comparison_j1_table[~comparison_j1_table['Model'].str.contains('XGBoost|ML')].copy()

    if len(baseline_j1_results) > 0:
        best_baseline_j1_idx = baseline_j1_results['Total_Cost_€'].idxmin()
        best_baseline_j1 = baseline_j1_results.loc[best_baseline_j1_idx]

        print(f"\nComparing ML vs Best Baseline ({best_baseline_j1['Model']})...")

        # Technical improvements
        rmse_improvement_j1 = ((best_baseline_j1['RMSE'] - ml_j1_results['RMSE']) / best_baseline_j1['RMSE']) * 100
        smape_improvement_j1 = ((best_baseline_j1['SMAPE'] - ml_j1_results['SMAPE']) / best_baseline_j1['SMAPE']) * 100

        # Business improvements
        fill_rate_improvement_j1 = ml_j1_results['Fill_Rate_%'] - best_baseline_j1['Fill_Rate_%']
        fill_rate_improvement_pct_j1 = (fill_rate_improvement_j1 / best_baseline_j1['Fill_Rate_%']) * 100

        stockout_reduction_j1 = best_baseline_j1['Stockout_Rate_%'] - ml_j1_results['Stockout_Rate_%']
        stockout_reduction_pct_j1 = (stockout_reduction_j1 / best_baseline_j1['Stockout_Rate_%']) * 100

        # Cost savings
        cost_savings_j1 = best_baseline_j1['Total_Cost_€'] - ml_j1_results['Total_Cost_€']
        cost_savings_pct_j1 = (cost_savings_j1 / best_baseline_j1['Total_Cost_€']) * 100

        print(f"\nTechnical: RMSE {rmse_improvement_j1:+.2f}%, SMAPE {smape_improvement_j1:+.2f}%")
        print(f"Service: Fill Rate {fill_rate_improvement_j1:+.2f}pp, Stockout {stockout_reduction_j1:+.2f}pp")
        print(f"Cost: €{cost_savings_j1:,.2f} ({cost_savings_pct_j1:+.2f}%)")

        improvement_summary_j1 = pd.DataFrame({
            'Metric': ['RMSE', 'SMAPE', 'Fill Rate', 'Stockout Rate', 'Total Cost'],
            'Baseline': [
                best_baseline_j1['RMSE'],
                best_baseline_j1['SMAPE'],
                best_baseline_j1['Fill_Rate_%'],
                best_baseline_j1['Stockout_Rate_%'],
                best_baseline_j1['Total_Cost_€']
            ],
            'ML_Model': [
                ml_j1_results['RMSE'],
                ml_j1_results['SMAPE'],
                ml_j1_results['Fill_Rate_%'],
                ml_j1_results['Stockout_Rate_%'],
                ml_j1_results['Total_Cost_€']
            ],
            'Improvement': [
                f"{rmse_improvement_j1:+.2f}%",
                f"{smape_improvement_j1:+.2f}%",
                f"{fill_rate_improvement_j1:+.2f}pp",
                f"{stockout_reduction_j1:+.2f}pp",
                f"€{cost_savings_j1:,.2f}"
            ]
        })

# ============================================================================
# 6. PREPARE EXPORT DATAFRAMES
# ============================================================================
print("\n" + "=" * 80)
print("[6] PREPARING DATA FOR EXPORT")
print("=" * 80)

# SKU Segmentation
print("\n[6.1] SKU Segmentation...")
sku_params['CV'] = sku_params['std_demand'] / (sku_params['avg_demand'] + 1e-10)
sku_params['ABC_XYZ_Class'] = sku_params['ABC_Class'].astype(str) + "_" + sku_params['XYZ_Class'].astype(str)

avg_inventory_by_sku = xgb_sim_df.groupby('SKU_ID')['avg_inventory'].first().reset_index()
sku_params = sku_params.merge(avg_inventory_by_sku, on='SKU_ID', how='left')

total_units_by_sku = df.groupby('SKU_ID')['Units_Sold'].sum().reset_index()
total_units_by_sku.columns = ['SKU_ID', 'total_units_sold']
sku_params = sku_params.merge(total_units_by_sku, on='SKU_ID', how='left')

sku_segmentation = sku_params[[
    'SKU_ID', 'ABC_Class', 'XYZ_Class', 'ABC_XYZ_Class',
    'avg_demand', 'std_demand', 'CV', 'avg_lead_time',
    'avg_inventory', 'total_units_sold'
]].copy()

print(f"SKU segmentation: {len(sku_segmentation)} SKUs")

# Forecast Results j+1
print("\n[6.2] Forecast Results j+1...")
forecast_j1_export = test_df_clean[[
    'Date', 'SKU_ID', 'Units_Sold',
    'Baseline_Naive', 'Baseline_Naive_Season', 'Baseline_MA7', 'Baseline_Dataset',
    'Pred_XGB_j1'
]].copy()

forecast_j1_export['Error_Naive'] = forecast_j1_export['Units_Sold'] - forecast_j1_export['Baseline_Naive']
forecast_j1_export['Error_XGB'] = forecast_j1_export['Units_Sold'] - forecast_j1_export['Pred_XGB_j1']

print(f"Forecast j+1: {len(forecast_j1_export)} rows")

# Simulation Results j+1
print("\n[6.3] Simulation Results j+1...")
simulation_j1_export_list = []

for model_name, sim_df in [
    ('Naïve (j-1)', naive_sim_df),
    ('Naïve Season (j-7)', naive_season_sim_df),
    ('Moving Avg (7d)', ma_sim_df),
    ('Dataset Forecast', dataset_sim_df),
    ('XGBoost ML', xgb_sim_df)
]:
    sim_copy = sim_df.copy()
    sim_copy['Model'] = model_name
    simulation_j1_export_list.append(sim_copy)

simulation_j1_export = pd.concat(simulation_j1_export_list, ignore_index=True)
simulation_j1_export = simulation_j1_export[[
    'Model', 'SKU_ID', 'ABC_Class', 'XYZ_Class',
    'fill_rate', 'stockout_rate', 'holding_cost', 'stockout_cost', 'total_cost',
    'total_demand', 'total_served', 'total_unmet'
]]

print(f"Simulation j+1: {len(simulation_j1_export)} rows")

# Forecast Results j+7
print("\n[6.4] Forecast Results j+7...")
forecast_j7_export = test_df_clean[[
    'Date', 'SKU_ID', 'Units_Sold',
    'Baseline_Naive', 'Baseline_Naive_Season', 'Baseline_MA7', 'Baseline_Dataset',
    'Pred_XGB_j7'
]].copy()

forecast_j7_export['Error_Naive'] = forecast_j7_export['Units_Sold'] - forecast_j7_export['Baseline_Naive']
forecast_j7_export['Error_XGB_j7'] = forecast_j7_export['Units_Sold'] - forecast_j7_export['Pred_XGB_j7']

print(f"Forecast j+7: {len(forecast_j7_export)} rows")

# Simulation Results j+7
print("\n[6.5] Simulation Results j+7...")
simulation_j7_export_list = []

for model_name, sim_df in [
    ('Naïve (j-1)', naive_sim_df),
    ('Naïve Season (j-7)', naive_season_sim_df),
    ('Moving Avg (7d)', ma_sim_df),
    ('Dataset Forecast', dataset_sim_df),
    ('XGBoost ML (j+7)', xgb_j7_sim_df)
]:
    sim_copy = sim_df.copy()
    sim_copy['Model'] = model_name
    simulation_j7_export_list.append(sim_copy)

simulation_j7_export = pd.concat(simulation_j7_export_list, ignore_index=True)
simulation_j7_export = simulation_j7_export[[
    'Model', 'SKU_ID', 'ABC_Class', 'XYZ_Class',
    'fill_rate', 'stockout_rate', 'holding_cost', 'stockout_cost', 'total_cost',
    'total_demand', 'total_served', 'total_unmet'
]]

print(f"Simulation j+7: {len(simulation_j7_export)} rows")
# ============================================================================
# 7. CREATE VALIDATION REPORT
# ============================================================================
print("\n[7] CREATING VALIDATION REPORT...")

validation_lines = []
validation_lines.append("=" * 80)
validation_lines.append("DEMAND FORECASTING & SUPPLY CHAIN - VALIDATION REPORT")
validation_lines.append("=" * 80)
validation_lines.append(f"\nGenerated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

validation_lines.append("\n" + "-" * 80)
validation_lines.append("1. DATA PREPROCESSING")
validation_lines.append("-" * 80)
validation_lines.append(f"Total rows: {len(df):,}")
validation_lines.append(f"Unique SKUs: {df['SKU_ID'].nunique():,}")
validation_lines.append(f"Date range: {df['Date'].min()} to {df['Date'].max()}")
validation_lines.append(f"Training: {train_df['Date'].min()} to {train_df['Date'].max()}")
validation_lines.append(f"Test: {test_df['Date'].min()} to {test_df['Date'].max()}")

validation_lines.append("\n" + "-" * 80)
validation_lines.append("2. MISSING VALUES")
validation_lines.append("-" * 80)
validation_lines.append("- Units_Sold: Filled with 0")
validation_lines.append("- Inventory_Level: Forward-filled per SKU")
validation_lines.append("- Supplier_Lead_Time_Days: Imputed with supplier median")
validation_lines.append("- Engineered features: Filled with 0")

validation_lines.append("\n" + "-" * 80)
validation_lines.append("3. MODEL CONFIG")
validation_lines.append("-" * 80)
validation_lines.append(f"Model: XGBoost")
validation_lines.append(f"Horizons: j+1, j+7, j+14")
validation_lines.append(f"CV: 5-fold Time Series")
validation_lines.append(f"Features: {len(all_model_features)}")

validation_lines.append("\n" + "-" * 80)
validation_lines.append("4. SIMULATION PARAMETERS")
validation_lines.append("-" * 80)
validation_lines.append(f"Annual storage rate: 20%")
validation_lines.append(f"Penalty factor: 1.5")
validation_lines.append(f"Service levels: A=90%, B=85%, C=80%")
validation_lines.append(f"Use dataset ROP: {use_dataset_ROP}")
validation_lines.append(f"Monte Carlo: {n_mc_top if 'n_mc_top' in locals() else 1000} (top), {n_mc_other if 'n_mc_other' in locals() else 200} (others)")
validation_lines.append(f"Random seed: 42")

validation_lines.append("\n" + "-" * 80)
validation_lines.append("5. KEY RESULTS")
validation_lines.append("-" * 80)
if 'best_baseline_j1' in locals():
    validation_lines.append(f"Horizon j+1:")
    validation_lines.append(f"  Best baseline: {best_baseline_j1['Model']}")
    validation_lines.append(f"  ML RMSE improvement: {rmse_improvement_j1:+.2f}%")
    validation_lines.append(f"  Cost savings: €{cost_savings_j1:,.2f}")

if 'best_baseline_j7' in locals() and 'rmse_improvement_j7' in locals():
    validation_lines.append(f"Horizon j+7:")
    validation_lines.append(f"  Best baseline: {best_baseline_j7['Model']}")
    validation_lines.append(f"  ML RMSE improvement: {rmse_improvement_j7:+.2f}%")
    validation_lines.append(f"  Cost savings: €{cost_savings_j7:,.2f}")

validation_lines.append("\n" + "=" * 80)
validation_lines.append("END OF REPORT")
validation_lines.append("=" * 80)

validation_text = "\n".join(validation_lines)

print("Validation report created")

# ============================================================================
# 8. EXPORT TO EXCEL
# ============================================================================
print("\n" + "=" * 80)
print("[8] EXPORTING TO EXCEL")
print("=" * 80)

output_filename = 'demand_forecasting_supply.xlsx'

print(f"\nCreating: {output_filename}...")

with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:

    # j+1 Horizon Sheets
    forecast_j1_export.head(10000).to_excel(writer, sheet_name='Forecast_J1', index=False)
    print("  Sheet 'Forecast_J1'")

    simulation_j1_export.to_excel(writer, sheet_name='Simulation_J1', index=False)
    print("  Sheet 'Simulation_J1'")

    comparison_j1_table.to_excel(writer, sheet_name='KPI_J1', index=False)
    print("  Sheet 'KPI_J1'")

    # j+7 Horizon Sheets
    forecast_j7_export.head(10000).to_excel(writer, sheet_name='Forecast_J7', index=False)
    print("  Sheet 'Forecast_J7'")

    simulation_j7_export.to_excel(writer, sheet_name='Simulation_J7', index=False)
    print("  Sheet 'Simulation_J7'")

    if 'comparison_j7_table' in globals():
        comparison_j7_table.to_excel(writer, sheet_name='KPI_J7', index=False)
        print("  Sheet 'KPI_J7'")

    # SKU Segmentation
    sku_segmentation.to_excel(writer, sheet_name='SKU_Segmentation', index=False)
    print("  Sheet 'SKU_Segmentation'")

    # Monte Carlo (if available)
    if 'mc_combined_df' in globals() and len(mc_combined_df) > 0:
        mc_combined_df.to_excel(writer, sheet_name='Monte_Carlo', index=False)
        print("  Sheet 'Monte_Carlo'")

    # Metadata
    metadata_df = pd.DataFrame({
        'Parameter': [
            'annual_storage_rate',
            'penalty_factor',
            'service_level_A',
            'service_level_B',
            'service_level_C',
            'use_dataset_ROP',
            'use_dataset_order_qty',
            'random_seed',
            'cv_folds',
            'forecast_horizons',
            'n_mc_top',
            'n_mc_other'
        ],
        'Value': [
            0.20,
            1.5,
            '90% (z=1.28)',
            '85% (z=1.06)',
            '80% (z=0.84)',
            use_dataset_ROP,
            use_dataset_order_qty if 'use_dataset_order_qty' in locals() else True,
            42,
            5,
            'j+1, j+7, j+14',
            n_mc_top if 'n_mc_top' in locals() else 1000,
            n_mc_other if 'n_mc_other' in locals() else 200
        ]
    })
    metadata_df.to_excel(writer, sheet_name='Metadata', index=False)
    print("  Sheet 'Metadata'")

print(f"\nExcel file created: {output_filename}")

# ============================================================================
# 9. EXPORT ADDITIONAL FILES
# ============================================================================
print("\n[9] EXPORTING ADDITIONAL FILES...")

# Quick check CSV
quick_check_filename = 'quick_check.csv'
forecast_j1_export.head(100).to_csv(quick_check_filename, index=False)
print(f"Quick check: {quick_check_filename}")

# Validation report
validation_filename = 'validation_report.txt'
with open(validation_filename, 'w') as f:
    f.write(validation_text)
print(f"Validation report: {validation_filename}")

# Full forecast CSV
forecast_full_filename = 'forecast_results_full.csv'
forecast_j1_export.to_csv(forecast_full_filename, index=False)
print(f"Full forecast: {forecast_full_filename}")

# ============================================================================
# 10. FINAL SUMMARY
# ============================================================================
print("\n" + "=" * 80)
print("BLOCK E COMPLETE")
print("=" * 80)

print("\nFILES GENERATED:")
print(f"  1. {output_filename}")
print(f"  2. {quick_check_filename}")
print(f"  3. {validation_filename}")
print(f"  4. {forecast_full_filename}")

print("\nEXCEL STRUCTURE:")
print("  Forecast_J1 - Daily forecasts (horizon j+1)")
print("  Simulation_J1 - Inventory simulations (horizon j+1)")
print("  KPI_J1 - Comparison table (horizon j+1)")
print("  Forecast_J7 - Daily forecasts (horizon j+7)")
print("  Simulation_J7 - Inventory simulations (horizon j+7)")
print("  KPI_J7 - Comparison table (horizon j+7)")
print("  SKU_Segmentation - ABC/XYZ classification")
print("  Monte_Carlo - Stochastic simulation results")
print("  Metadata - Configuration parameters")

if 'best_baseline_j1' in locals():
    print("\n" + "=" * 80)
    print("BUSINESS IMPACT SUMMARY")
    print("=" * 80)

    print(f"\nHORIZON j+1 (Short-term):")
    print(f"  Best Baseline: {best_baseline_j1['Model']}")
    print(f"  RMSE: {rmse_improvement_j1:+.2f}%")
    print(f"  Fill Rate: {fill_rate_improvement_j1:+.2f}pp")
    print(f"  Cost Savings: €{cost_savings_j1:,.2f} ({cost_savings_pct_j1:+.2f}%)")

    if 'best_baseline_j7' in locals() and 'rmse_improvement_j7' in locals():
        print(f"\nHORIZON j+7 (Medium-term):")
        print(f"  Best Baseline: {best_baseline_j7['Model']}")
        print(f"  RMSE: {rmse_improvement_j7:+.2f}%")
        print(f"  Fill Rate: {fill_rate_improvement_j7:+.2f}pp")
        print(f"  Cost Savings: €{cost_savings_j7:,.2f} ({cost_savings_pct_j7:+.2f}%)")

print("\nANSWER: Does ML forecasting reduce costs and improve service?")
if 'cost_savings_j1' in locals() and cost_savings_j1 > 0:
    print(f"  YES at j+1: €{cost_savings_j1:,.0f} savings, {fill_rate_improvement_j1:.2f}pp fill rate improvement")
    if 'cost_savings_j7' in locals() and cost_savings_j7 > 0:
        print(f"  YES at j+7: €{cost_savings_j7:,.0f} savings, {fill_rate_improvement_j7:.2f}pp fill rate improvement")

print("\n" + "=" * 80)
print("PROJECT COMPLETE - ALL 5 BLOCKS EXECUTED")
print("=" * 80)

print("\nSUMMARY:")
print("  Block A - Data Loading & Preprocessing")
print("  Block B - Feature Engineering & Baselines")
print("  Block C - Forecast Models & Metrics")
print("  Block D - Inventory Simulation & Monte Carlo")
print("  Block E - Business Impact & Export")

print("\nThe complete demand forecasting and supply chain optimization system is ready")
print("All results exported and ready for dashboard integration")

# [8.1] Import Colab files module
from google.colab import files

# [8.2] Liste de tous les fichiers générés à télécharger
files_to_download = [
    'demand_forecasting_supply.xlsx',  # Excel principal avec forecast, simulation, KPI
    'quick_check.csv',                 # 100 premières lignes pour vérification rapide
    'validation_report.txt'            # Rapport des imputations et valeurs manquantes
]

# [8.3] Boucle pour télécharger chaque fichier
for f in files_to_download:
    try:
        files.download(f)
        print(f"✅ Téléchargement lancé pour : {f}")
    except Exception as e:
        print(f"⚠️ Erreur lors du téléchargement de {f} : {e}")